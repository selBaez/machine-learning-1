{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Linear Regression and Overfitting\n",
    "\n",
    "### Machine Learning and Pattern Recognition, September 2016\n",
    "\n",
    "* The lab exercises should be made in groups of two people.\n",
    "* The deadline is sunday September 25, 23:59.\n",
    "* Assignment should be sent to your teaching assistant. The subject line of your email should be \"\\#lab\\_lastname1\\_lastname2\\_lastname3\".\n",
    "* Put your and your teammates' names in the body of the email\n",
    "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file follows the same rule as the subject line. For example, if the subject line is \"lab01\\_Kingma\\_Hu\", the attached file should be \"lab01\\_Kingma\\_Hu.ipynb\". Only use underscores (\"\\_\") to connect names, otherwise the files cannot be parsed.\n",
    "* Make sure we can run your notebook / scripts!\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your teaching assistant.\n",
    "* Please write your answers right below the questions.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Refer to last week's lab notes, i.e. http://docs.scipy.org/doc/, if you are unsure about what function to use. There are different correct ways to implement each problem!\n",
    "* For this lab, your regression solutions should be in closed form, i.e., should not perform iterative gradient-based optimization but find the exact optimum directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "def fit_model(x,t,M,lamb=0.0):\n",
    "    weights = []\n",
    "    poly_xes = []\n",
    "    for i in np.arange(M.shape[0]):\n",
    "        if lamb == 0.0:\n",
    "            poly_w,poly_x = fit_polynomial(x,t,M[i])\n",
    "            weights.append(poly_w)\n",
    "            poly_xes.append(poly_x)\n",
    "        else:\n",
    "            poly_w,poly_x = fit_polynomial_reg(x,t,M[i],lamb)\n",
    "            weights.append(poly_w)\n",
    "            poly_xes.append(poly_x)\n",
    "    print len(weights) , ' the number of weights vectors'\n",
    "    print len(poly_xes) , ' the number of models'\n",
    "    return weights,poly_xes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\bPhi}{\\mathbf{\\Phi}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bm}{\\mathbf{m}}$\n",
    "$\\newcommand{\\bS}{\\mathbf{S}}$\n",
    "$\\newcommand{\\bI}{\\mathbf{I}}$\n",
    "\n",
    "## Part 1: Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generate sinusoidal data (5 points)\n",
    "Write a method `gen_sinusoidal(N)` that generates toy data like in fig 1.2 of Bishop's book. The method should have a parameter $N$, and should return $N$-dimensional vectors $\\bx$ and $\\bt$, where $\\bx$ contains evenly spaced values from 0 to (including) 2$\\pi$, and the elements $t_i$ of $\\bt$ are distributed according to:\n",
    "\n",
    "$$t_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)$$\n",
    "\n",
    "where $x_i$ is the $i$-th elements of $\\bf{x}$, the mean $\\mu_i = sin(x_i)$ and the standard deviation $\\sigma = 0.2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_sinusoidal(N):\n",
    "    print 'generating sin polynomial data'\n",
    "    sigma = 0.2\n",
    "    #CREATE EVENLY SPACED VALUES IN [0,2Ï€] SPACE\n",
    "    x = np.linspace(0,2*np.pi,N)\n",
    "    # SINCE THE NP.RANDOM.NORMAL TAKES THE STANDARD DEVIATION WE \n",
    "    t = np.random.normal(loc=np.sin(x),scale=sigma)\n",
    "    return x,t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Polynomial regression (15 points)\n",
    "\n",
    "Write a method `fit_polynomial(x, t, M)` that finds the maximum-likelihood solution of an _unregularized_ $M$-th order polynomial for some dataset `x`. The error function to minimize w.r.t. $\\bw$ is:\n",
    "\n",
    "$E(\\bw) = \\frac{1}{2} (\\bPhi\\bw - \\bt)^T(\\bPhi\\bw - \\bt)$\n",
    "\n",
    "where $\\bPhi$ is the _feature matrix_ (or _design matrix_) as explained in Bishop's book at section 3.1.1, $\\bt$ is the vector of target values. Your method should return a vector $\\bw$ with the maximum-likelihood parameter estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error\n",
    "def fit_polynomial(x,t,M,verbose=False,iters=2):\n",
    "    N = x.shape[0]\n",
    "    print 'data points',N,'polynomial size:',M\n",
    "    phi = np.zeros((N,M+1))\n",
    "    \n",
    "    for i in range(M+1):\n",
    "            #print i ,'is the iteration'\n",
    "            \n",
    "        phi[:,i] = np.power(x,i)\n",
    "    \n",
    "    #print phi,x\n",
    "\n",
    "    w = np.dot(np.linalg.inv(np.dot(phi.T,phi)),np.dot(phi.T,t))   \n",
    "      \n",
    "    return w,phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plot (5 points)\n",
    "Sample a dataset with $N=9$, and fit four polynomials with $M \\in (0, 1, 3, 9)$.\n",
    "For each value of $M$, plot the prediction function, along with the data and the original sine function. The resulting figure should look similar to fig 1.4 of the Bishop's book. Note that you can use matplotlib's `plt.pyplot(.)` functionality for creating grids of figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sin polynomial data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d542b7ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 9\n",
    "np.set_printoptions(precision=3)\n",
    "x,t = gen_sinusoidal(N)\n",
    "M = np.array([0,1,3,9])\n",
    "#Toy visualization\n",
    "plt.scatter(x,t,color='green',alpha=1,s=45,facecolors='none')\n",
    "plt.title('Scatter plot of the toy sin function with N =%s datapoints'%(N));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-32e3ed37c00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoly_xes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mplot_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoly_xes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_prediction(poly_w,poly_x,x,t):\n",
    "    axes = []\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col')\n",
    "    axes.append(ax1)\n",
    "    axes.append(ax2)\n",
    "    axes.append(ax3)\n",
    "    axes.append(ax4)\n",
    "    # print poly_xes\n",
    "    # print polynomials\n",
    "    for i in np.arange(M.shape[0]):\n",
    "        #print M[i]\n",
    "        axes[i].plot(x,np.sin(x),color='lightgreen')\n",
    "        axes[i].scatter(x,t,facecolor='none')\n",
    "        axes[i].plot(x,poly_x[i].dot(poly_w[i]),color='red')\n",
    "        axes[i].set_title('Polynomial fit for M=%u'%(M[i]))\n",
    "        \n",
    "        \n",
    "weights,poly_xes = fit_model(x,t,M)\n",
    "plot_prediction(weights,poly_xes,x,t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Regularized linear regression (10 points)\n",
    "\n",
    "Write a method `fit_polynomial_reg(x, t, M, lamb)` that fits a _regularized_ $M$-th order polynomial to the sinusoidal data, as discussed in the lectures, where `lamb` is the regularization term _lambda_. (Note that 'lambda' cannot be used as a variable name in Python since it has a special meaning). The error function to minimize w.r.t. $\\bw$:\n",
    "\n",
    "$E(\\bw) = \\frac{1}{2} (\\bPhi\\bw - \\bt)^T(\\bPhi\\bw - \\bt) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}$\n",
    "\n",
    "For background, see section 3.1.4 of Bishop's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_reg(x,t,M,lamb):\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    print 'data points',N,'polynomial size:',M ,'regularization parameter:',lamb\n",
    "    phi = np.zeros((N,M+1))\n",
    "    for i in range(M+1):\n",
    "            #print i ,'is the iteration'\n",
    "            \n",
    "        phi[:,i] = np.power(x,i)\n",
    "    \n",
    "    w = np.dot(np.linalg.inv(lamb*np.eye(M+1)+np.dot(phi.T,phi)),np.dot(phi.T,t))    \n",
    "    return w,phi\n",
    "\n",
    "# fit_polynomial_reg(x,t,M[0],0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points 9 polynomial size: 0 regularization parameter: 0.001\n",
      "data points 9 polynomial size: 1 regularization parameter: 0.001\n",
      "data points 9 polynomial size: 3 regularization parameter: 0.001\n",
      "data points 9 polynomial size: 9 regularization parameter: 0.001\n",
      "4  the number of weights vectors\n",
      "4  the number of models\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d2ed13690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly_w_reg,poly_x_reg = fit_model(x,t,M,lamb=0.001)\n",
    "plot_prediction(poly_w_reg,poly_x_reg,x,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Model selection by cross-validation (10 points)\n",
    "Use cross-validation to find a good choice of $M$ and $\\lambda$, given a dataset of $N=9$ datapoints generated with `gen_sinusoidal(9)`. You should write a function that tries (loops over) a reasonable range of choices of $M$ and $\\lambda$, and returns the choice with the best cross-validation error. In this case you can use $K=9$ folds, corresponding to _leave-one-out_ crossvalidation.\n",
    "\n",
    "You can let $M \\in (0, 1, ..., 10)$, and let $\\lambda \\in (e^{-10}, e^{-9}, ..., e^{0})$.\n",
    "\n",
    "To get you started, here's a method you can use to generate indices of cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kfold_indices(N, k):\n",
    "    all_indices = np.arange(N,dtype=int)\n",
    "    np.random.shuffle(all_indices)\n",
    "    idx = np.floor(np.linspace(0,N,k+1))\n",
    "    train_folds = []\n",
    "    valid_folds = []\n",
    "    for fold in range(k):\n",
    "        valid_indices = all_indices[idx[fold]:idx[fold+1]]\n",
    "        valid_folds.append(valid_indices)\n",
    "        train_folds.append(np.setdiff1d(all_indices, valid_indices))\n",
    "    return train_folds, valid_folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a comprehensible plot of the cross-validation error for each choice of $M$ and $\\lambda$. Highlight the best choice. \n",
    "\n",
    "_Question_: Explain over-fitting and underfitting, illuminated by your plot. Explain the relationship with model bias and model variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 1 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 2 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 3 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 4 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 5 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 6 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 7 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 8 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 9 regularization parameter: 4.53999297625e-05\n",
      "data points 8 polynomial size: 10 regularization parameter: 4.53999297625e-05\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000123409804087\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000123409804087\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000335462627903\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000335462627903\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.000911881965555\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.000911881965555\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00247875217667\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00247875217667\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.00673794699909\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.00673794699909\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0183156388887\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0183156388887\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.0497870683679\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.0497870683679\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.135335283237\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.135335283237\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 1 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 2 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 3 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 4 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 5 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 6 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 7 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 8 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 9 regularization parameter: 0.367879441171\n",
      "data points 8 polynomial size: 10 regularization parameter: 0.367879441171\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "data points 8 polynomial size: 0 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 1 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 2 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 3 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 4 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 5 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 6 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 7 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 8 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 9 regularization parameter: 1.0\n",
      "data points 8 polynomial size: 10 regularization parameter: 1.0\n",
      "11  the number of weights vectors\n",
      "11  the number of models\n",
      "total number of models: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cts/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "M_fold = np.linspace(0,10,11).astype(int)\n",
    "l_fold = np.exp(np.linspace(-10,0,11))\n",
    "K = 9\n",
    "x_ind,t_ind =  kfold_indices(N,K)\n",
    "weights_k_fold = []\n",
    "poly_x_k_fold = []\n",
    "x_folds = []\n",
    "t_folds = []\n",
    "v_folds = []\n",
    "for k in range(K):\n",
    "    x_fold = x[x_ind[k]]\n",
    "    t_fold = t[x_ind[k]]\n",
    "    v_fold = t[t_ind[k]]\n",
    "    x_folds.append(x_fold)\n",
    "    t_folds.append(t_fold)\n",
    "    v_folds.append(v_fold)\n",
    "    #M = np.array([M_fold[k]]).astype(int)\n",
    "    #lamb = np.array([l_fold[k]])\n",
    "    for j in range(M_fold.shape[0]):\n",
    "        weights,poly_x = fit_model(x_fold,t_fold,M_fold,l_fold[j])\n",
    "        weights_k_fold.append(weights)\n",
    "        poly_x_k_fold.append(poly_x)\n",
    "print 'total number of models:', len(weights_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Plot best cross-validated fit (5 points)\n",
    "\n",
    "For some dataset with $N = 9$, plot the model with the optimal $M$ and $\\lambda$ according to the cross-validation error, using the method you just wrote. Let the plot make clear which $M$ and $\\lambda$ were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "8\n",
      "8\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[[ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]\n",
      " [ 0.072]]\n",
      "[[ 0.675 -0.   ]\n",
      " [ 0.675 -0.156]\n",
      " [ 0.675 -0.311]\n",
      " [ 0.675 -0.467]\n",
      " [ 0.675 -0.623]\n",
      " [ 0.675 -0.934]\n",
      " [ 0.675 -1.09 ]\n",
      " [ 0.675 -1.245]]\n",
      "[[ 0.725 -0.     0.   ]\n",
      " [ 0.725 -0.2    0.006]\n",
      " [ 0.725 -0.401  0.022]\n",
      " [ 0.725 -0.601  0.05 ]\n",
      " [ 0.725 -0.801  0.088]\n",
      " [ 0.725 -1.202  0.198]\n",
      " [ 0.725 -1.402  0.27 ]\n",
      " [ 0.725 -1.602  0.352]]\n",
      "[[  0.188   0.     -0.      0.   ]\n",
      " [  0.188   1.013  -0.415   0.036]\n",
      " [  0.188   2.026  -1.659   0.286]\n",
      " [  0.188   3.039  -3.733   0.966]\n",
      " [  0.188   4.052  -6.636   2.291]\n",
      " [  0.188   6.077 -14.931   7.731]\n",
      " [  0.188   7.09  -20.323  12.277]\n",
      " [  0.188   8.103 -26.544  18.326]]\n",
      "[[  2.193e-01   0.000e+00  -0.000e+00   0.000e+00   0.000e+00]\n",
      " [  2.193e-01   8.445e-01  -3.071e-01   1.436e-02   1.325e-03]\n",
      " [  2.193e-01   1.689e+00  -1.229e+00   1.149e-01   2.121e-02]\n",
      " [  2.193e-01   2.534e+00  -2.764e+00   3.877e-01   1.074e-01]\n",
      " [  2.193e-01   3.378e+00  -4.914e+00   9.191e-01   3.393e-01]\n",
      " [  2.193e-01   5.067e+00  -1.106e+01   3.102e+00   1.718e+00]\n",
      " [  2.193e-01   5.912e+00  -1.505e+01   4.926e+00   3.182e+00]\n",
      " [  2.193e-01   6.756e+00  -1.966e+01   7.353e+00   5.429e+00]]\n",
      "[[  2.522e-01   0.000e+00   0.000e+00  -0.000e+00   0.000e+00  -0.000e+00]\n",
      " [  2.522e-01   3.182e-01   2.747e-01  -1.993e-01   3.264e-02  -1.585e-03]\n",
      " [  2.522e-01   6.364e-01   1.099e+00  -1.595e+00   5.222e-01  -5.072e-02]\n",
      " [  2.522e-01   9.546e-01   2.472e+00  -5.382e+00   2.644e+00  -3.851e-01]\n",
      " [  2.522e-01   1.273e+00   4.395e+00  -1.276e+01   8.355e+00  -1.623e+00]\n",
      " [  2.522e-01   1.909e+00   9.889e+00  -4.305e+01   4.230e+01  -1.232e+01]\n",
      " [  2.522e-01   2.227e+00   1.346e+01  -6.837e+01   7.836e+01  -2.664e+01]\n",
      " [  2.522e-01   2.546e+00   1.758e+01  -1.021e+02   1.337e+02  -5.194e+01]]\n",
      "[[  2.573e-01   0.000e+00   0.000e+00  -0.000e+00   0.000e+00  -0.000e+00\n",
      "    0.000e+00]\n",
      " [  2.573e-01   6.256e-02   6.704e-01  -4.124e-01   8.418e-02  -7.325e-03\n",
      "    2.396e-04]\n",
      " [  2.573e-01   1.251e-01   2.682e+00  -3.299e+00   1.347e+00  -2.344e-01\n",
      "    1.533e-02]\n",
      " [  2.573e-01   1.877e-01   6.034e+00  -1.113e+01   6.818e+00  -1.780e+00\n",
      "    1.747e-01]\n",
      " [  2.573e-01   2.503e-01   1.073e+01  -2.639e+01   2.155e+01  -7.501e+00\n",
      "    9.814e-01]\n",
      " [  2.573e-01   3.754e-01   2.413e+01  -8.908e+01   1.091e+02  -5.696e+01\n",
      "    1.118e+01]\n",
      " [  2.573e-01   4.379e-01   3.285e+01  -1.415e+02   2.021e+02  -1.231e+02\n",
      "    2.819e+01]\n",
      " [  2.573e-01   5.005e-01   4.291e+01  -2.111e+02   3.448e+02  -2.400e+02\n",
      "    6.281e+01]]\n",
      "[[  2.580e-01  -0.000e+00   0.000e+00  -0.000e+00   0.000e+00  -0.000e+00\n",
      "    0.000e+00  -0.000e+00]\n",
      " [  2.580e-01  -3.382e-01   1.503e+00  -1.035e+00   3.062e-01  -4.802e-02\n",
      "    3.940e-03  -1.322e-04]\n",
      " [  2.580e-01  -6.764e-01   6.012e+00  -8.283e+00   4.900e+00  -1.537e+00\n",
      "    2.521e-01  -1.692e-02]\n",
      " [  2.580e-01  -1.015e+00   1.353e+01  -2.796e+01   2.480e+01  -1.167e+01\n",
      "    2.872e+00  -2.891e-01]\n",
      " [  2.580e-01  -1.353e+00   2.405e+01  -6.626e+01   7.839e+01  -4.917e+01\n",
      "    1.614e+01  -2.166e+00]\n",
      " [  2.580e-01  -2.029e+00   5.411e+01  -2.236e+02   3.969e+02  -3.734e+02\n",
      "    1.838e+02  -3.700e+01]\n",
      " [  2.580e-01  -2.367e+00   7.365e+01  -3.551e+02   7.352e+02  -8.070e+02\n",
      "    4.635e+02  -1.089e+02]\n",
      " [  2.580e-01  -2.706e+00   9.619e+01  -5.301e+02   1.254e+03  -1.573e+03\n",
      "    1.033e+03  -2.772e+02]]\n",
      "[[  2.587e-01   0.000e+00   0.000e+00   0.000e+00  -0.000e+00   0.000e+00\n",
      "   -0.000e+00   0.000e+00  -0.000e+00]\n",
      " [  2.587e-01   5.783e-02   4.435e-01   4.279e-02  -2.445e-01   1.065e-01\n",
      "   -2.017e-02   1.824e-03  -6.428e-05]\n",
      " [  2.587e-01   1.157e-01   1.774e+00   3.423e-01  -3.912e+00   3.410e+00\n",
      "   -1.291e+00   2.335e-01  -1.645e-02]\n",
      " [  2.587e-01   1.735e-01   3.992e+00   1.155e+00  -1.980e+01   2.589e+01\n",
      "   -1.471e+01   3.990e+00  -4.217e-01]\n",
      " [  2.587e-01   2.313e-01   7.096e+00   2.738e+00  -6.259e+01   1.091e+02\n",
      "   -8.263e+01   2.989e+01  -4.212e+00]\n",
      " [  2.587e-01   3.470e-01   1.597e+01   9.242e+00  -3.169e+02   8.285e+02\n",
      "   -9.412e+02   5.107e+02  -1.080e+02]\n",
      " [  2.587e-01   4.048e-01   2.173e+01   1.468e+01  -5.870e+02   1.791e+03\n",
      "   -2.373e+03   1.502e+03  -3.705e+02]\n",
      " [  2.587e-01   4.627e-01   2.838e+01   2.191e+01  -1.001e+03   3.491e+03\n",
      "   -5.288e+03   3.826e+03  -1.078e+03]]\n",
      "[[  2.590e-01   0.000e+00   0.000e+00   0.000e+00  -0.000e+00  -0.000e+00\n",
      "    0.000e+00  -0.000e+00   0.000e+00  -0.000e+00]\n",
      " [  2.590e-01   2.409e-01   1.548e-01   4.939e-02  -3.691e-02  -4.277e-02\n",
      "    2.737e-02  -6.041e-03   5.938e-04  -2.199e-05]\n",
      " [  2.590e-01   4.817e-01   6.191e-01   3.951e-01  -5.906e-01  -1.369e+00\n",
      "    1.752e+00  -7.733e-01   1.520e-01  -1.126e-02]\n",
      " [  2.590e-01   7.226e-01   1.393e+00   1.333e+00  -2.990e+00  -1.039e+01\n",
      "    1.995e+01  -1.321e+01   3.896e+00  -4.329e-01]\n",
      " [  2.590e-01   9.635e-01   2.476e+00   3.161e+00  -9.449e+00  -4.380e+01\n",
      "    1.121e+02  -9.898e+01   3.891e+01  -5.765e+00]\n",
      " [  2.590e-01   1.445e+00   5.572e+00   1.067e+01  -4.784e+01  -3.326e+02\n",
      "    1.277e+03  -1.691e+03   9.973e+02  -2.216e+02]\n",
      " [  2.590e-01   1.686e+00   7.584e+00   1.694e+01  -8.862e+01  -7.188e+02\n",
      "    3.220e+03  -4.975e+03   3.423e+03  -8.875e+02]\n",
      " [  2.590e-01   1.927e+00   9.906e+00   2.529e+01  -1.512e+02  -1.401e+03\n",
      "    7.175e+03  -1.267e+04   9.962e+03  -2.952e+03]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (8,1) into shape (8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6550cbb64b4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#print weights_k_fold[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mplot_prediction_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_k_fold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoly_x_k_fold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-6550cbb64b4f>\u001b[0m in \u001b[0;36mplot_prediction_cv\u001b[1;34m(poly_w, poly_x, x, t, M)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lightgreen'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoly_x\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpoly_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Polynomial fit for M=%u'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (8,1) into shape (8)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNfOHEhuPn9pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d2e112ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_prediction_cv(poly_w,poly_x,x,t,M):\n",
    "    axes = []\n",
    "    f, ((ax1, ax2,ax3, ax4,ax5),(ax6,ax7,ax8,ax9,ax10)) = plt.subplots(2,5 , sharex='col')\n",
    "    axes.append(ax1)\n",
    "    axes.append(ax2)\n",
    "    axes.append(ax3)\n",
    "    axes.append(ax4)\n",
    "    axes.append(ax5)\n",
    "    axes.append(ax6)\n",
    "    axes.append(ax7)\n",
    "    axes.append(ax8)\n",
    "    axes.append(ax9)\n",
    "    axes.append(ax10)\n",
    "    # print poly_xes\n",
    "    # print polynomials\n",
    "    print len(poly_w)\n",
    "    print len(poly_x)\n",
    "    print len(x)\n",
    "    print len(t)\n",
    "    print M\n",
    "    poly_w = np.array(poly_w)\n",
    "    for i in np.arange(M.shape[0]-1):\n",
    "        xx = poly_x[i]\n",
    "        #print xx\n",
    "        ww = poly_w[i]\n",
    "        #print ww\n",
    "        print xx*ww\n",
    "    for i in np.arange(M.shape[0]-1):\n",
    "        #print M[i]\n",
    "        \n",
    "        axes[i].plot(x,np.sin(x),color='lightgreen')\n",
    "        axes[i].scatter(x,t,facecolor='none')\n",
    "        axes[i].plot(x,poly_x*poly_w,color='red')\n",
    "        axes[i].set_title('Polynomial fit for M=%u'%(M[i]))\n",
    "    \n",
    "#print weights_k_fold[0]\n",
    "plot_prediction_cv(weights_k_fold[0],poly_x_k_fold[0],x_folds[0],t_folds[0],M_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bayesian Linear (Polynomial) Regression\n",
    "\n",
    "### 2.1 Sinusoidal data 2 (5 points)\n",
    "\n",
    "Write a function `gen_sinusoidal2(N)` that behaves identically to `gen_sinusoidal(N)` except that the generated values $x_i$ are not linearly spaced, but drawn from a uniform distribution between $0$ and $2 \\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sin polynomial data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHkhJREFUeJzt3XmUFOW9//H3l31VUQMBEVwSl+BPgxpF0ThqVCQiasxV\n0Ov2i8ejl59GY4IxRoj3el3uMYsx0RhXVETjEhA1FxXGJXEBDS4EBDdAEFRAQSAymfn+/niegZ6m\ne6aH7pnq6fq8zpkz3U9XV32ruurT1U9VdZu7IyIila9d0gWIiEjrUOCLiKSEAl9EJCUU+CIiKaHA\nFxFJCQW+iEhKKPBbiZnVmdkurTStO81spZm91Izhr2rpulqKmY02s78U8fxmLa9SMbMnzOzfW3Oa\nzZl+W10vzGycmd2TdB1NMbObzexnrTnNsgp8MzvEzP5qZp+Z2adm9ryZ7VfkOM80s+ez2pJYkQu6\n4CFXvc1hZocARwL93H1IqcdfwPRnmNk5LTX+XNx9orsP25LnNrW8SiWG0ITMNncf7u6JBVPm9Euw\n3g2MOzVTs9rvMbMrt2B8PzCzBWa2Or4x9W3mKArd3hJ7U3P389396kKGLVWdZRP4ZtYTeAz4DdAL\n2AH4BfBlsaOmwBe/4BGatd/COgodrph6dwI+cPd/ttD4K81ONL680qJU68WBZlbUG6eZVQFXAyOA\nbYEPgPuLrkzA3cviD9gPWNnEMOcC/wBWA28B34ztY4F3MtpPiO17AOuBGmANsDKOYwPwzzj85Dhs\nX+Ah4GPgXeD/ZUx3HPAn4B7gM+CcHLXdCdwMTIvjnQEMyHi8Dtgl3t4KmBCn9T7ws3z15lkOfYHJ\nwApgPvCD2H5OxvNXA+Oynpdz/LH2m4Cp8XkvAjtnPW9anN5c4Pt56vov4F/AujieG2P7wcArwCrg\nZeCg2H4yMCtrHJcAj+YZ/1nxtVkd/4+K7WcCz2ct6/PislkJ3JRnfJstr+xx5XjtmlpWgzKW1UfA\nZcAxhB2XL+Ny/3scdkb9ukQI3CsI4bYMuAvYKj42MNZwBrAwrjeX55mnnYBVGff/CCzPuD8BuDBz\n+lu6XmRNt77GHwPTM9rvAa5sZhb8T+ZrRljf6xqZ9k5ANfA58L/Ab4EJGY8/GF+LVXG4PTPyJFcW\n5MyTPNOuz4ZJcfhZwN5Z286MOO03gRFZmXFVvH0YsJiw/i8HlgBnFVDnh7FtLnB4k8u2OS9ES/4B\nPYFP4oo+DNgm6/HvxwWyb7y/C7BjvP09oE/GcF9k3D8TeC5rXBsXdMbGNgv4GdA+rkDvAEdlvKhf\n1r9YQOcc9d8ZV7ihQEfg12weQvWhMQF4FOhG2FDeBs7OV2+OaT0XV+qOwD6EAKgq5PmNLI9PCG+6\n7YB7gYnxsW7AIkLYWMb09sgz/o0hFu/3IoTu6DjuU+P9XkAn4FNg94zhXyPHBhbr+Bz4Wrzfh00b\nboN5ist6Slyndoz1Hl3I8sizfGppGPj5llUPYCnwwzhv3YFvZaxDE/ItK0Lwzo/rQzfg4frh2RSm\nf4jj3Zuw8e+eZ54+AAbH2/MI6/Lu8f5CYiBlTb9Z60WOaQ6My6k7IYSOiO0bAz++Fqvi678q6/ZK\n4NQ4XHbg7xDnf0Seaf8tPqcjcCghADMD/6y4TDsCvyS+4ebKgqbyJMe067PhREJ2/Ah4L97uACwg\nBHMH4PBY29ezp00I/Jo4vvbAscBaYOs8mbUbYbusr3MAed4QM//KpkvH3dcAhxBe2FuBj81sspl9\nJQ7yf4Hr3f21OPx77r443n7Y3ZfH238iLOQDmjH5bwHbu/vV7l7r7h8AtxHCqd6L7v5YnEa+bqbH\n3f2v7l5DePM4yMx2yBzAzNoBpwCXufs6d18I3AAUdPDOzPoDBwFj3b3G3V+PtZ5R6Mzm8ai7v+ru\ndcB9wDdj+3HA++4+wYPXgUcIG0IhvgvM99DPXufukwghNMLdNxD2vk6P8zaIEByP5xlXLfB/zKyL\nuy9397mNTPcad18T15EZGfOzJbK74/ItqxHAR+7+a3ff4O5r3X1mgdMYDfzS3Re6+zrgp8CpcX2B\n0N0yPo73DeB1wptvLs8Bh5lZn3j/oXh/J6BnfH6h8s1rPusJ3TH/lf2Auy92917uvm38n3l727hu\nAPwF+L6Z7WVmXYErCbnQLXucZrYjsD/hTaXG3Z8ndA1nTveuuK3VAFcB+8Qu5Jy2IE9edfdH3b2W\n8IbSGRgS/7q7+3Xu/i93n0H4tDQqz3g2AP8ZM+hJwhvN7nmGrSW8+e9lZh3cfZG7v99IjUAZ9eED\nuPvb7n6Ouw8A9gL6EfaUIewdvJvreWZ2hpn93cxWmdkqwsfq7Zsx6YHADvFMjZVxHD8FemcMs7iA\n8Wwcxt3XEvZa+mUNsz3h3X5RRttCwl5MIfoRPnKv28Ln57Ms4/Y6wt4qhGUzJGvZjAa+2ox6F2a1\nZdZ7dxwfhOB/MG6YDcT5PQU4H/jIzB4zs3wbA4SPxbnmpxTyLav+5FlHC5C9nBYS1pM+GW2FztOz\nhL3Jb8fb1UAVYS+yuQdm881rY24D+pjZcc2cFgDu/gwwnrBj8V78W0P45JCtH6ELa31G28blaGbt\nzOxaM3vHzD4jdKE6jeTDFuRJ5nbvhO6YfvEvOzca21ZXxDfWenmXt7u/S/gkOR5YbmYTCzmwXVaB\nn8nd5xO6d/aKTYuBXbOHM7MBhE8EF9TvNQBz2LRX5rlGn3V/MfBe3Muo3+PY2t1HNPKcXHbMqKsH\n4YDTkqxhPiV8dBuY0TYwY7imprMU2NbMume0DcgxnXwKmY9Mi4HqrGWzlbv/R4HjX0roIsu0sV53\nfxnYYGaHEoI/71kr7v6Uux9NeLN5m/C6l9paMvYkzazQNzbIs45Ghbyu2etEDQ1DvlDPEro2Dou3\n/0roaqy/vyX1FSy+Yf8C+M/MdjPb0czWxDNvMv/q20ZljONmd9/N3fsSgr8DoT8920dAr/hJoN6A\njNunET55HeHu2xDWRSNPPhSQJ7lkbvdGeONfGv8GZA3bnG0102avj7tPcvdD2bTeXNvUSMom8M1s\ndzO7pL4LJH5UG0U4UARhr+FSM9s3Pr5rHKY74ePep/Hd/Gw2vUlA2GD6m1nHrLbMc+JfAdaY2U/M\nrIuZtTezQWa2fzNnY7iZHWxmnQgr+4vuvjRzgPgO/iBwtZn1MLOBwMVsCrpc9WY+/0NCn+U1ZtbZ\nzPYmdHcVenpfo+PPYSqwm5mdbmYdzKyjme1vZns0Mv7MZfsE8HUzOzUu11OAPeN4691DODi4wd3/\nlmukZtbbzI43s26EIPyC8LqX2uvAIDPb28w6E/pUCw3DqcBXzexCM+sUX9/6roDlwE4xEHK5H7jY\nzHaKOwtXA5My9vgKPcsLd3+H0LVyOvBs7C5dDpxE/sBv7nqRS2aN9wJdCH3R9XUtdveecYch86++\n7X6AuF4PirfrA/jX7v55jnldRDj+9ou4bh5CCPh6PQh97KviTtI1NHw9s9fXpvIkl/3M7IR49t7F\nhOMrLxFOUFgbc6VDPPvoOLbsjKMGdZrZbmZ2eMyaDYTXu8ntoWwCn/CR7UDgZTNbQwi1N4BLAdz9\nIcJGMNHMVhMOem4b+3FvICzgZYSPXy9kjHc64R16mZl9HNtuJ2zUK83skbhRHUfon3yfcJDvj4Sz\naZpjIuEj1gpgMLFvOspcyS4kfFx7j9Dfeq+739lIvdlGATsT9iAeBn4e+wcLUcj4NxXt/gVwNOF4\nRv1ey7WE/sNcfkPof11hZr9295WEZXsp4dPNpcB3Y3u9ewgbVWNvWu0IZzAsieP5NqF7J2fZTdzP\ny90XEPp5nyEcRC24CyQuq6OA4wnr4nxCVwqEMzkMWGFms3LUdQdh/p8jdAutI6wn+eahqXl6FvjU\n3Zdk3IdwUDzXOJq1XuSxcXxxm7qScHC+uZ8euhC28zWE7fqvcVz5jCb0l68Afk7oJqw3gdB9uoTw\nCSF7hyI7C+YS+uHz5UkukwndjasInyhOjP3wNYQ3n+GEdfYm4N/jOlaIzOXWoE7C9nct4aD6UuAr\nhG7oRlnociqOmd1O2KiXu/veeYa5kU1Hns9y99lFT7iMmNmdwGJ3b/ZFJmlnZl0IezD7xr5JkTbB\nzMYBu7p7sSdNtIpS7eHfSTjXOCczO5awUL5OOD/6lhJNVyrDBcBMhb1Iy+pQipG4+wuxLzqfkYSP\nVrj7y2a2tZn1qT/1qUKU7KBXmphZ/alkJyRaiEgKlCTwC7ADDU9PWhLbKibw3b1Vvz+mUrj7zknX\nILKl3P0XSdfQHOV00FZERFpQa+3hLyHjXFXCeao5z0U1M3WNiIg0k7s3eepuKffwMy9myDaFeOm/\nhW/S+6yx/ntv4vsg2urfuHHjEq9B86f50/xV3l+hSrKHb2YTCecbb2dmiwgXq3QK2e23uvsTZjbc\nzN4hnJZ5dimmKyIihSvVWTqjCxhmTCmmJSIiW0YHbVtRVVVV0iW0KM1f26b5q3wludK2lMzMy60m\nEZFyZmZ4Kx+0FRGRMqbAFxFJCQW+iEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ikRGt9eZpIq1i3DiZM\ngKlToX17OOkkGDUKOuX7QUaRFNGFV1Ix1qyBI46A3r3hnHOgpgZuuQU6dIDHH4fOnZOuUKRlFHrh\nlQJfKsb48bBgAdx7L1hc9WtrYfhwGDkSLrgg0fJEWoyutJXUefBBuPjiTWEPoVvnoovCYyJpp8CX\nirF+PfTsuXl7z57hMZG0U+BLxTj6aJg4cfP2++4Lj4mknc7SkYoxdiwMHQpdumw6aPv738OTT8Ir\nryRdnUjytIcvFWOXXeDZZ2HOHNh9d9hnH/jkE3jhBejTJ+nqRJKns3RERNo4naUjIiINKPBFRFJC\ngS8ikhIKfBGRlFDgi4ikhAJfRCQlFPgiIimhwBcRSQkFvohISijwRURSQoGfYosWhe+PHzwYvv1t\n+MMfwheOiUhlUuCn1Lx5cOCB0LFjCPqxY2HSJDj55PArUSJSefTlaSl14olw6KFwySWb2mpqYMgQ\nuPLK8JOAItI26DdtJa9//Qu6d4cVK6BHj4aP3XwzvPwy3HVXIqWJyBbQt2VKo9yhXY5Xv317qKtr\n/XpEpOUp8FOoQ4fwk3/Ze/G1tXDHHXD88YmUJSItTD9xmFL//d/wne+Ebp2TT4ZPP4Xrrgs/+H3C\nCUlXJyItQX34KTZ/Plx/PVRXw1ZbwejRMGZM+E1YEWk7dNBWRCQldNBWREQaUOCLiKSEAl9EJCUU\n+CIiKaHAFxFJCQW+iEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ikREkC38yGmdk8M5tvZmNzPH6YmX1m\nZq/FvytKMV0RESlc0d+WaWbtgJuAI4GlwEwzm+zu87IGfc7d9cW7IiIJKcUe/gHAAndf6O41wCQg\n1w/kNfnFPiIi0nJKEfg7AIsz7n8Y27IdZGazzexxM/tGCaYrUtHq6sLvDIuUSmv9AMqrwAB3X2dm\nxwJ/BnbLN/D48eM33q6qqqKqqqql6xMpG8uWweWXwwMPwJdfwsEHw1VXgTYDqVddXU11dXWzn1f0\n9+Gb2RBgvLsPi/cvA9zdr2vkOe8D+7n7yhyP6fvwJbXWrIH994eRI+HHP4ZttoFHHoELL4QHH4TD\nDku6QilHhX4ffin28GcCXzOzgcBHwKnAqKxi+rj78nj7AMIbzWZhL5J2EybAoEHhl8jqnXJK6N4Z\nPx5mzEisNKkARQe+u9ea2RhgGuGYwO3uPtfMzgsP+63AyWZ2PlADrAdOKXa6IpWoujr8xnC2730P\nTj89BH87XT0jW6gkffju/hdg96y2P2Tc/h3wu1JMS6SS9ewJn3yyefuKFdCtG5jOdZMiaF9BpIyM\nHg2/+x2sXr2pzR2uuQZOO02BL8VprbN0RKQARx4JxxwD++0H558P220XDtYuXBi6e0SKUfRZOqWm\ns3Qk7dxDuN9/P3zxBRx+eNi779Yt6cqkXBV6lo4CX0SkjSs08NWHLyKSEgp8EZGUUOCLiKSEAl9E\nJCUU+CIiKaHAFxFJCQW+iEhK6EpbkZSorYUpU+BPf4ING2DYsHBBV9euSVcmrUUXXomkQG0tjBoF\n774bvrKhWze45x74+GOYPh223jrpCqUYutJWRDaaOBFuvBGefRY6dw5t7nD22dCnD1yX9+eKpC1Q\n4IvIRscfH76J89RTG7bPmQPDh4cvZ5O2S1+tICIbrV0LvXpt3r7ttuExSQcFvkgKHHlk+FH0bJMm\nhcckHdSlI5ICK1aEH0cfPRouumjTQdsrr4RnnoG99066QimGunREZKPttoPnn4elS2GXXUJXzpNP\nwrRpCvs00R6+SAq56+cSK4n28EUkL4V9OinwRURSQoEvIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIp\nocAXEUkJBb6ISEoo8EVEUkKBLyKSEgp8EZGUUOCLiKSEAl9EJCUU+CIiKaHAFxFJCQW+iEhKKPBF\nRFJCgS8ikhIKfBGRlFDgi4ikhAJfRCQlFPgiIimhwBcRSQkFvohISijwRURSQoEvIpISJQl8Mxtm\nZvPMbL6Zjc0zzI1mtsDMZpvZN0sxXRERKVzRgW9m7YCbgGOAQcAoM9sja5hjgV3d/evAecAtxU5X\nRESapxR7+AcAC9x9obvXAJOAkVnDjAQmALj7y8DWZtanBNMWEZEClSLwdwAWZ9z/MLY1NsySHMOI\niEgL6pB0AbmMHz9+4+2qqiqqqqoSq0VEpNxUV1dTXV3d7OeZuxc1YTMbAox392Hx/mWAu/t1GcPc\nAsxw9wfi/XnAYe6+PMf4vNiaRETSxMxwd2tquFJ06cwEvmZmA82sE3AqMCVrmCnAGbGwIcBnucJe\nRERaTtFdOu5ea2ZjgGmEN5Db3X2umZ0XHvZb3f0JMxtuZu8Aa4Gzi52uiIg0T9FdOqWmLh0RkeZp\nzS4dERFpAxT4IiIpocAXEUkJBb6ISEoo8EVEUkKBLyKSEgp8EZGUUOCLiKREWX55moiUhw0b4JFH\noLoaevSA0aNh332Trkq2lPbwRSSnVavgoIPglltgr71C4B9/PIwbl3RlsqX01QoiktMFF0BdHdx8\nM1i8aP+TT2D//eH+++Hgg5OtTzYp9KsVFPgishl32HprmDcP+vVr+Nj118P774c3AikP+i4dEdli\ntbWwbh30yfFDpP36he4eaXsU+CKymQ4dYL/9YOrUzR+bPBmGDm39mqR4OktHRHIaNw5+8APo0gWO\nOgq++AJ+9St47TW4/fakq5MtoT78hCxaBLNmwXbbwSGHQPv2SVcksrkpU+DnPw999nV1MHw43HAD\n7Lhj0pVJJh20LVMbNsD558Of/xyCftEiWLMGJk0KZz+IlBv30GffpQt065Z0NZJLoYGvLp1WdsUV\nsGwZLFwYzmsGePhhOO44ePvtcGaESDkxg223TboKKQXt4bei9euhf3+YPXvzj8SnnAKHHRbOfRZJ\n0oYN8MAD4eAswMiRYf3s1CnZuiQ/7eGXoY8/hu7dc/d/HnggLFjQ+jWJZFq/PvTTu4cDtgC33QZ3\n3AFPPAFduyZbnxRHp2W2ot69w5kOS5Zs/tisWbDrrq1fk0imm28OOyXTp8Ppp4e/6dND2+9/n3R1\nUiwFfivq2hXOPBPGjIF//nNT+9Sp8PTTcNppydUmAuHkgR/9CNplJEO7dqHtgQeSq0tKQ106reza\na+Gcc2DAADj88HDwdunS0F/aq1fS1UnarVsH22yzefs228Data1fj5SWAr+Vde4M990X+utnzoTt\nt4cjjghXNook7TvfCXv5gwc3bJ80KVx8JW2bztIRkY0WLYIhQ0K343nnhbZbb4Xf/hZeeil8MpXy\noy9PE5FmGzAAnnsO5swJtwcMgLfeCm0K+7ZPe/giIm2c9vBFRKQBBb6ISEoo8EVEUkKBLyKSEgp8\nEZGUUOCLiKSEAl9EJCUU+CIiKaHAFxFJCQW+iEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ikhAJfRCQl\nFPgiIimhwBcRSQkFvohISijwRURSQoEvIpISHYp5spn1Ah4ABgIfAP/m7p/nGO4D4HOgDqhx9wOK\nma6IiDRfsXv4lwFPu/vuwHTgp3mGqwOq3H2wwl5EJBnFBv5I4O54+27ghDzDWQmmJSIiRSg2hHu7\n+3IAd18G9M4znANPmdlMMzu3yGmKiMgWaLIP38yeAvpkNhEC/Iocg3ue0Qx194/M7CuE4J/r7i/k\nm+b48eM33q6qqqKqqqqpMkVEUqO6uprq6upmP8/c82V0AU82m0vom19uZl8FZrj7nk08Zxywxt1/\nmedxL6YmEZF6X34JN9wAd98NK1fCQQfB5ZfDkCFJV1ZaZoa7W1PDFdulMwU4K94+E5ico5BuZtYj\n3u4OHA28VeR0RUQaVVcHJ5wAL74I994Lb74JI0bAyJHwzDNJV5eMok7LBK4DHjSzc4CFwL8BmFlf\n4I/ufhyhO+hRM/M4vfvcfVqR0xURadS0abB0Kbz6KnSISXfuudC7N/zkJzBrFliT+8SVpagunZag\nLh0RKYUf/hD69oWxYxu219XBdtvB22+H8K8ErdWlIyJSljp1gvXrN2+vqYHaWujYsfVrSpoCX0Qq\n0sknw113werVDdvvvBMOPBB69UqkrEQV24cvIlKWDjgAjjsOhg6FSy+FHXeExx6D+++Hp59Ourpk\nqA9fRCqWO0yZEvb060/LHDMG+vdPurLSKrQPX4EvItLG6aCtiIg0oMAXEUkJBb6ISEoo8EVEUkKB\nLyKSEgp8EZGUUOCLiKSEAl9EJCUU+CIiKaHAFxFJCQW+iEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ik\nhAJfRCQlFPgiIimhwBeRNqGmBq65BnbeGTp1gm99Cx56KOmq2hb9iLmItAlnngmffgqPPgp77AEz\nZoTfp12xAs47L+nq2gb9pq2IlL3Zs2HECFiwALp02dQ+Zw4ccQQsWgSdOydXX9L0m7YiUjGefhpO\nOqlh2AMMGgR9+8IbbyRTV1ujwBeRste1K3z++ebt7qG9W7fWr6ktUuCLSNk76SSYPBk++KBh+8MP\nQ48e8I1vJFJWm6ODtiJS9vr2hauvhqFD4cILYc89Yfp0mDgRpkwBa7L3WkAHbUWkDZk5E267DZYs\ngX32CWfnDBiQdFXJK/SgrQJfRKSN01k6IiLSgAJfRCQlFPgiIimhwBcRSQkFvohISijwRURSQoEv\nIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIpocAXEUkJBb6ISEoo8EVEUkKBLyKSEkUFvpmdbGZvmVmt\nme3byHDDzGyemc03s7HFTFNERLZMsXv4bwInAs/mG8DM2gE3AccAg4BRZrZHkdNtk6qrq5MuoUVp\n/to2zV/lKyrw3f1td18ANPZLKwcAC9x9obvXAJOAkcVMt62q9BVO89e2af4qX2v04e8ALM64/2Fs\nExGRVtShqQHM7CmgT2YT4MDP3P2xlipMRERKqyQ/Ym5mM4AfuftrOR4bAox392Hx/mWAu/t1ecal\nXzAXEWmmQn7EvMk9/GbIN7GZwNfMbCDwEXAqMCrfSAopWkREmq/Y0zJPMLPFwBBgqpk9Gdv7mtlU\nAHevBcYA04A5wCR3n1tc2SIi0lwl6dIREZHyV3ZX2hZ6MVdbU8kXn5nZ7Wa23MzeSLqWlmBm/c1s\nupnNMbM3zezCpGsqFTPrbGYvm9nf47yNS7qmlmBm7czsNTObknQtpWZmH5jZ6/E1fKWxYcsu8Cng\nYq62JgUXn91JmLdK9S/gEncfBBwE/EelvH7u/iVwuLsPBr4JHGtmByRcVku4CPhH0kW0kDqgyt0H\nu3ujr13ZBX6BF3O1NRV98Zm7vwCsSrqOluLuy9x9drz9BTCXCrqWxN3XxZudCSdyVFQ/r5n1B4YD\ntyVdSwsxCszysgv8CqWLzyqEme1E2BN+OdlKSid2d/wdWAY85e4zk66pxH4F/JgKeyPL4MBTZjbT\nzM5tbMBSnpZZMF3MJW2RmfUAHgIuinv6FcHd64DBZrYV8Gcz+4a7V0T3h5l9F1ju7rPNrIrK6jmo\nN9TdPzKzrxCCf2781L2ZRALf3Y9KYroJWgIMyLjfP7ZJG2FmHQhhf4+7T066npbg7qvjRZTDqJz+\n7qHA8WY2HOgK9DSzCe5+RsJ1lYy7fxT/f2JmjxK6kHMGfrl36VTKu/HGi8/MrBPh4rNKO1vAqJzX\nK5c7gH+4+2+SLqSUzGx7M9s63u4KHAXMS7aq0nH3y919gLvvQtjupldS2JtZt/jJEzPrDhwNvJVv\n+LIL/HwXc7VllX7xmZlNBP4G7GZmi8zs7KRrKiUzGwqcBhwRT317zcyGJV1XifQFZpjZbMJxif91\n9ycSrkkK1wd4IR6DeQl4zN2n5RtYF16JiKRE2e3hi4hIy1Dgi4ikhAJfRCQlFPgiIimhwBcRSQkF\nvohISijwRURSQoEvIpIS/x+mwjfZ4KMAzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d2c529290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_sinusoidal2(N):\n",
    "    print 'generating sin polynomial data'\n",
    "    sigma = 0.2\n",
    "    #CREATE EVENLY SPACED VALUES IN [0,2Ï€] SPACE\n",
    "    x = np.random.uniform(0,2*np.pi,N)\n",
    "    # SINCE THE NP.RANDOM.NORMAL TAKES THE STANDARD DEVIATION WE \n",
    "    t = np.random.normal(loc=np.sin(x),scale=sigma)\n",
    "    return x,t\n",
    "N = 9\n",
    "x,t = gen_sinusoidal2(N)\n",
    "plt.scatter(x,t,color='blue',alpha=1,s=45,facecolors='none')\n",
    "plt.title('Scatter plot of the toy sin function with N=%s data points'%(N));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute Posterior (15 points)\n",
    "\n",
    "You're going to implement a Bayesian linear regression model, and fit it to the sinusoidal data. Your regression model has a zero-mean isotropic Gaussian prior over the parameters, governed by a single (scalar) precision parameter $\\alpha$, i.e.:\n",
    "\n",
    "$$p(\\bw \\;|\\; \\alpha) = \\mathcal{N}(\\bw \\;|\\; 0, \\alpha^{-1} \\bI)$$\n",
    "\n",
    "The covariance and mean of the posterior are given by:\n",
    "\n",
    "$$\\bS_N= \\left( \\alpha \\bI + \\beta \\bPhi^T \\bPhi \\right)^{-1} $$\n",
    "$$\\bm_N = \\beta\\; \\bS_N \\bPhi^T \\bt$$\n",
    "\n",
    "where $\\alpha$ is the precision of the predictive distribution, and $\\beta$ is the noise precision. \n",
    "See MLPR chapter 3.3 for background.\n",
    "\n",
    "Write a method `fit_polynomial_bayes(x, t, M, alpha, beta)` that returns the mean $\\bm_N$ and covariance $\\bS_N$ of the posterior for a $M$-th order polynomial, given a dataset, where `x`, `t` and `M` have the same meaning as in question 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sin polynomial data\n",
      "data points 9 polynomial size: 3\n",
      "[[ 30.122 -36.42   12.26   -1.245]\n",
      " [-36.42   51.241 -19.344   2.156]\n",
      " [ 12.26  -19.344   8.202  -1.002]\n",
      " [ -1.245   2.156  -1.002   0.131]] [ 0.698  0.791 -0.433  0.039]\n"
     ]
    }
   ],
   "source": [
    "def fit_polynomial_bayes(x, t, M, alpha, beta):\n",
    "    N = x.shape[0]\n",
    "    print 'data points',N,'polynomial size:',M\n",
    "    phi = np.zeros((N,M+1))\n",
    "    for i in range(M+1):\n",
    "        phi[:,i] = np.power(x,i)\n",
    "    \n",
    "    cov = np.linalg.inv(alpha*np.eye(M+1)+ beta*np.dot(phi.T,phi))\n",
    "    mu  = beta*np.dot(cov,phi.T).dot(t)\n",
    "    return cov,mu,phi\n",
    "\n",
    "x,t = gen_sinusoidal2(9)\n",
    "cov,mu,poly_x = fit_polynomial_bayes(x,t,3,0.01,25)\n",
    "print cov,mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prediction (10 points)\n",
    "\n",
    "The predictive distribution of Bayesian linear regression is:\n",
    "\n",
    "$$ p(t \\;|\\; \\bx, \\bt, \\alpha, \\beta) = \\mathcal{N}(t \\;|\\; \\bm_N^T \\phi(\\bx), \\sigma_N^2(\\bx))$$\n",
    "\n",
    "$$ \\sigma_N^2 = \\frac{1}{\\beta} + \\phi(\\bx)^T \\bS_N \\phi(\\bx) $$\n",
    "\n",
    "where $\\phi(\\bx)$ are the computed features for a new datapoint $\\bx$, and $t$ is the predicted variable for datapoint $\\bx$. \n",
    "\n",
    "Write a function that `predict_polynomial_bayes(x, m, S, beta)` that returns the predictive mean and variance given a new datapoint `x`, posterior mean `m`, posterior variance `S` and a choice of model variance `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_polynomial_bayes(x,m,S,beta):\n",
    "    \n",
    "    M = mu.shape[0]\n",
    "    N = x.shape[0]\n",
    "    phi = np.zeros((N,M+1))\n",
    "    for i in range(M+1):\n",
    "        phi[:,i] = np.power(x,i)\n",
    "    new_s = 1/beta + np.dot(phi.T,S).dot(phi)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Plot predictive distribution (10 points)\n",
    "\n",
    "a) (5 points) Generate 7 datapoints with `gen_sinusoidal2(7)`. Compute the posterior mean and covariance for a Bayesian polynomial regression model with $M=5$, $\\alpha=\\frac{1}{2}$ and $\\beta=\\frac{1}{0.2^2}$.\n",
    "Plot the Bayesian predictive distribution, where you plot (for $x$ between 0 and $2 \\pi$) $t$'s predictive mean and a 1-sigma predictive variance using `plt.fill_between(..., alpha=0.1)` (the alpha argument induces transparency).\n",
    "\n",
    "Include the datapoints in your plot.\n",
    "\n",
    "b) (5 points) For a second plot, draw 100 samples from the parameters' posterior distribution. Each of these samples is a certain choice of parameters for 5-th order polynomial regression. \n",
    "Display each of these 100 polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Additional questions (10 points)\n",
    "\n",
    "a) (5 points) Why is $\\beta=\\frac{1}{0.2^2}$ the best choice of $\\beta$ in section 2.4?\n",
    "\n",
    "b) (5 points) In the case of Bayesian linear regression, both the posterior of the parameters $p(\\bw \\;|\\; \\bt, \\alpha, \\beta)$ and the predictive distribution $p(t \\;|\\; \\bw, \\beta)$ are Gaussian. In consequence (and conveniently), $p(t \\;|\\; \\bt, \\alpha, \\beta)$ is also Gaussian (See Bishop's book section 3.3.2 and homework 2 question 4). This is actually one of the (rare) cases where we can make Bayesian predictions without resorting to approximative methods.\n",
    "\n",
    "Suppose you have to work with some model $p(t\\;|\\;x,\\bw)$ with parameters $\\bw$, where the posterior distribution $p(\\bw\\;|\\;\\mathcal{D})$ given dataset $\\mathcal{D}$ can not be integrated out when making predictions, but where you can still generate samples from the posterior distribution of the parameters. Explain how you can still make approximate Bayesian predictions using samples from the parameters' posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
